!/usr/bin/env python3
"""
Quick RAG Tester for HOA Compliance
Run this with your actual HOA document to test different configurations
"""

import time
import os
from typing import List, Dict
import pandas as pd

# LangChain components
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Milvus, Chroma, FAISS

# Your HOA bylaws text from the uploaded document
HOA_BYLAWS = """
AMENDED AND RESTATED BYLAWS
OF
CAMINO PLACE HOMEOWNERS ASSOCIATION

ARTICLE 1 - NAME AND LOCATION
The name of the corporation is Camino Place Homeowners Association, which is hereinafter referred to as the "Association." The principal office of the Association shall be located in Santa Clara County, California, or such other place reasonably convenient to the Development as the Board of Directors may from time to time establish.

ARTICLE 2 - DEFINITIONS
2.1 Articles. "Articles" shall mean the Articles of Incorporation of Camino Place Homeowners Association, as they may be amended from time to time, and as filed with the Office of the Secretary of State of California.

2.2 Assessments. "Assessments" shall mean any or all of the following: Annual Assessments, Special Assessments, and Reimbursement Assessments, each as is defined in the Declaration.

[... Full document text from your upload would go here ...]

ARTICLE 4 - MEMBER MEETINGS AND VOTING
4.6 Voting. Members in Good Standing shall be entitled to cast one (1) vote for each Unit owned or, in the case of a vote to elect Directors, one vote for each open position on the Board. Votes of the Members on the following issues must be by secret ballot, conducted by means of a double envelope system pursuant to Civil Code section 5100 et seq.: Assessments legally requiring a vote of the Members, election and removal of members of the Board of Directors, amendments to the Governing Documents, or the grant of exclusive use of Common Area property.

ARTICLE 5 - BOARD OF DIRECTORS; ELECTION; TERM OF OFFICE
5.2 Qualifications for Candidates. Candidates for the Board: (i) must be Members in Good Standing, or, in the case of a Member in Good Standing that is an entity, an officer, director, principal, or authorized representative of the entity; (ii) may not have been declared of unsound mind by a final order of court; and (iii) may not have been convicted of a felony.

5.4 Election. Directors shall be elected annually by secret ballot in accordance with Civil Code sections 5100 through 5135 and Rules adopted pursuant thereto.
"""

# Compliance test questions
COMPLIANCE_QUESTIONS = [
    "How must HOA board elections be conducted under California law?",
    "What voting methods are required for board elections?",
    "What qualifications are required for board candidates?",
    "What notice requirements exist for board meetings?",
    "How are proxy votes handled in HOA elections?",
    "What constitutes a quorum for member meetings?",
    "How long do directors serve on the board?",
    "Under what circumstances can a director be removed?"
]

def setup_embeddings():
    """Setup different embedding models for testing"""
    models = {}
    
    # Test different embedding models
    embedding_configs = [
        ("MiniLM-L6", "sentence-transformers/all-MiniLM-L6-v2"),
        ("MiniLM-L12", "sentence-transformers/all-MiniLM-L12-v2"),
        ("MPNet-base", "sentence-transformers/all-mpnet-base-v2"),
    ]
    
    for name, model_id in embedding_configs:
        try:
            models[name] = HuggingFaceEmbeddings(
                model_name=model_id,
                encode_kwargs={'normalize_embeddings': True}
            )
            print(f"✓ Loaded {name}")
        except Exception as e:
            print(f"✗ Failed to load {name}: {e}")
    
    return models

def prepare_documents(text: str) -> List[Document]:
    """Prepare documents for vector storage"""
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=600,
        chunk_overlap=100,
        separators=["\nARTICLE ", "\n\n", "\n", ". ", " "]
    )
    
    docs = splitter.create_documents([text])
    
    # Add metadata to help with retrieval
    enhanced_docs = []
    for i, doc in enumerate(docs):
        content = doc.page_content.lower()
        metadata = {
            "chunk_id": i,
            "has_voting": "vote" in content or "ballot" in content,
            "has_director": "director" in content or "board" in content,
            "has_meeting": "meeting" in content,
            "has_california_law": "civil code" in content or "california" in content
        }
        enhanced_docs.append(Document(page_content=doc.page_content, metadata=metadata))
    
    return enhanced_docs

def test_vector_store(store_type: str, documents: List[Document], embeddings, store_name: str):
    """Test a specific vector store configuration"""
    print(f"\n--- Testing {store_name} with {store_type} ---")
    
    start_time = time.time()
    
    try:
        # Create vector store
        if store_type == "FAISS":
            vector_store = FAISS.from_documents(documents, embeddings)
        elif store_type == "Chroma":
            import chromadb
            collection_name = f"hoa_test_{int(time.time())}"
            vector_store = Chroma.from_documents(
                documents, 
                embeddings,
                collection_name=collection_name
            )
        elif store_type == "Milvus":
            from pymilvus import connections
            connections.connect("default", host="localhost", port="19530")
            collection_name = f"hoa_test_{int(time.time())}"
            vector_store = Milvus.from_documents(
                documents,
                embeddings,
                connection_args={"host": "localhost", "port": "19530"},
                collection_name=collection_name
            )
        else:
            return None
            
        setup_time = time.time() - start_time
        print(f"Setup time: {setup_time:.2f}s")
        
        # Test retrieval quality
        relevance_scores = []
        query_times = []
        
        for question in COMPLIANCE_QUESTIONS:
            q_start = time.time()
            try:
                results = vector_store.similarity_search(question, k=3)
                query_time = time.time() - q_start
                query_times.append(query_time)
                
                # Simple relevance scoring
                if results:
                    question_words = set(question.lower().split())
                    doc_text = " ".join([doc.page_content.lower() for doc in results])
                    doc_words = set(doc_text.split())
                    relevance = len(question_words.intersection(doc_words)) / len(question_words)
                    relevance_scores.append(relevance)
                    
                    # Show best result for first question
                    if question == COMPLIANCE_QUESTIONS[0]:
                        print(f"Sample result for '{question[:50]}...':")
                        print(f"  → {results[0].page_content[:200]}...")
                        print(f"  → Relevance: {relevance:.3f}")
                else:
                    relevance_scores.append(0)
                    
            except Exception as e:
                print(f"Query failed: {e}")
                query_times.append(float('inf'))
                relevance_scores.append(0)
        
        avg_relevance = sum(relevance_scores) / len(relevance_scores) if relevance_scores else 0
        avg_query_time = sum(query_times) / len(query_times) if query_times else float('inf')
        
        print(f"Average relevance score: {avg_relevance:.3f}")
        print(f"Average query time: {avg_query_time*1000:.1f}ms")
        
        # Calculate compliance score (weighted for legal accuracy)
        compliance_score = avg_relevance * 0.7 + (1.0 / (1.0 + avg_query_time)) * 0.3
        print(f"Compliance score: {compliance_score:.3f}")
        
        return {
            "embedding": store_name,
            "vector_store": store_type,
            "setup_time": setup_time,
            "avg_relevance": avg_relevance,
            "avg_query_time": avg_query_time,
            "compliance_score": compliance_score
        }
        
    except Exception as e:
        print(f"Failed to setup {store_type}: {e}")
        return None

def main():
    """Run the comparison"""
    print("HOA Compliance RAG Comparison")
    print("="*50)
    
    # Prepare documents
    documents = prepare_documents(HOA_BYLAWS)
    print(f"Prepared {len(documents)} document chunks")
    
    # Setup embeddings
    embedding_models = setup_embeddings()
    
    if not embedding_models:
        print("No embedding models loaded successfully!")
        return
    
    # Test configurations
    results = []
    vector_stores = ["FAISS", "Chroma", "Milvus"]
    
    for emb_name, embeddings in embedding_models.items():
        for vs_type in vector_stores:
            result = test_vector_store(vs_type, documents, embeddings, emb_name)
            if result:
                results.append(result)
    
    # Display results
    if results:
        df = pd.DataFrame(results).sort_values("compliance_score", ascending=False)
        print("\n" + "="*60)
        print("FINAL RANKINGS FOR HOA COMPLIANCE")
        print("="*60)
        
        for i, (_, row) in enumerate(df.iterrows(), 1):
            print(f"{i}. {row['embedding']} + {row['vector_store']}")
            print(f"   Compliance Score: {row['compliance_score']:.3f}")
            print(f"   Relevance: {row['avg_relevance']:.3f}")
            print(f"   Speed: {row['avg_query_time']*1000:.1f}ms")
            print()
        
        # Save results
        df.to_csv("hoa_rag_comparison.csv", index=False)
        print("Results saved to hoa_rag_comparison.csv")
        
        # Recommendations
        best = df.iloc[0]
        print(f"\n🏆 RECOMMENDATION FOR CALIFORNIA COMPLIANCE:")
        print(f"   Use {best['embedding']} + {best['vector_store']}")
        print(f"   This combination scored {best['
