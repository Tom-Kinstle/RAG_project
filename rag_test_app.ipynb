{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a42add0",
   "metadata": {},
   "source": [
    "# Proelections Concept Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27959127",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f417f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import torch\n",
    "import requests\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b33fd2a",
   "metadata": {},
   "source": [
    "## 2. Sample HOA File Links and Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0463b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote HOA file URLs\n",
    "FILE_MAP = {\n",
    "    \"arroyo park\": \"https://raw.githubusercontent.com/Tom-Kinstle/RAG_project/main/rag_test/arroyo_park.txt\",\n",
    "    \"camino place\": \"https://raw.githubusercontent.com/Tom-Kinstle/RAG_project/main/rag_test/camino_place.txt\",\n",
    "    \"jackson oaks\": \"https://raw.githubusercontent.com/Tom-Kinstle/RAG_project/main/rag_test/jackson_oaks.txt\"\n",
    "}\n",
    "\n",
    "# Compliance questions\n",
    "QUESTIONS = [\n",
    "    \"How must HOA board elections be conducted under California law?\",\n",
    "    \"What voting methods are required for board elections?\",\n",
    "    \"What qualifications are required for board candidates?\",\n",
    "    \"What notice requirements exist for board meetings?\",\n",
    "    \"How are proxy votes handled in HOA elections?\",\n",
    "    \"What constitutes a quorum for member meetings?\",\n",
    "    \"How long do directors serve on the board?\",\n",
    "    \"Under what circumstances can a director be removed?\",\n",
    "    \"What are the assessment collection procedures?\",\n",
    "    \"How are architectural review requests processed?\",\n",
    "    \"What enforcement actions can the HOA take for violations?\",\n",
    "    \"What are the requirements for amending CC&Rs or bylaws?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ab27c",
   "metadata": {},
   "source": [
    "## 3. Chunking Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bdfa2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk configs\n",
    "CHUNK_CONFIGS = {\n",
    "    \"default\": {\"size\": 800, \"overlap\": 200},\n",
    "    \"small\": {\"size\": 400, \"overlap\": 100},\n",
    "    \"large\": {\"size\": 1200, \"overlap\": 300}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d3e910",
   "metadata": {},
   "source": [
    "#### Sets up chunking strategies to slice text into overlapping segments for vectorization. Options vary in size and overlap, affecting the granularity of information retrieval.\n",
    "#### Chunk size affects the granularity. Smaller chunks increase resolution but may lose context; larger chunks preserve more but might dilute precision.\n",
    "\n",
    "#### Overlap helps preserve meaning that might be cut off at chunk boundaries — especially useful for legal text where a single sentence may span two chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e254f95b",
   "metadata": {},
   "source": [
    "## 4. Embedding Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0868c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E5-Base embedding setup\n",
    "def setup_embedding_model(silent: bool = False):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if not silent:\n",
    "        print(f\"🖥️ Using device: {device}\")\n",
    "    try:\n",
    "        return HuggingFaceEmbeddings(\n",
    "            model_name=\"intfloat/e5-base-v2\",\n",
    "            model_kwargs={\"device\": device},\n",
    "            encode_kwargs={\"normalize_embeddings\": True, \"batch_size\": 32}\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading E5: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba28aad",
   "metadata": {},
   "source": [
    "#### Initializes our E5-base model using HuggingFace, selection GPU if available. \n",
    "\n",
    "#### Embeddings are the semantic engine (HuggingFace) of this project. They allow the system to \"understand\" text by mapping it into high-dimensional space where similar meanings are nearby (KNN), regardless of exact phrasing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd9d689",
   "metadata": {},
   "source": [
    "## 5. Document Cleaning and Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfda5634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document prep (clean & chunked)\n",
    "def prepare_documents_enhanced(text: str, chunk_size: int, chunk_overlap: int) -> List[Document]:\n",
    "    lines = text.split('\\n')\n",
    "    cleaned_lines = []\n",
    "    skip_section = False\n",
    "\n",
    "    for line in lines:\n",
    "        if 'COMPLIANCE_QUESTIONS' in line or 'How must HOA board elections' in line:\n",
    "            skip_section = True\n",
    "            continue\n",
    "        if skip_section and (line.strip() == '' or line.startswith('    \"')):\n",
    "            continue\n",
    "        if skip_section and not line.startswith('    '):\n",
    "            skip_section = False\n",
    "        if not skip_section:\n",
    "            cleaned_lines.append(line)\n",
    "\n",
    "    cleaned_text = '\\n'.join(cleaned_lines)\n",
    "    if not cleaned_text.strip():\n",
    "        return []\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n=== \", \"\\nARTICLE \", \"\\nSECTION \", \"\\n\\n\", \"\\n\", \". \", \" \"],\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "    raw_docs = splitter.create_documents([cleaned_text])\n",
    "    enhanced_docs = []\n",
    "\n",
    "    for i, doc in enumerate(raw_docs):\n",
    "        content = doc.page_content.lower()\n",
    "        metadata = {\n",
    "            \"chunk_id\": i,\n",
    "            \"chunk_size\": len(doc.page_content),\n",
    "            \"has_voting\": any(t in content for t in [\"vote\", \"ballot\", \"election\", \"poll\", \"voting\", \"electoral\"]),\n",
    "            \"has_proxy\": \"proxy\" in content,\n",
    "            \"has_director\": any(t in content for t in [\"director\", \"board\", \"officer\", \"president\", \"secretary\", \"treasurer\"]),\n",
    "            \"has_quorum\": \"quorum\" in content,\n",
    "            \"has_notice\": any(t in content for t in [\"notice\", \"notification\", \"notify\", \"inform\"]),\n",
    "            \"has_meeting\": any(t in content for t in [\"meeting\", \"assembly\", \"session\", \"gathering\"]),\n",
    "        }\n",
    "        enhanced_docs.append(Document(page_content=doc.page_content, metadata=metadata))\n",
    "\n",
    "    return enhanced_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c2af3",
   "metadata": {},
   "source": [
    "#### This stage cleans and structures legal documents for semantic search. It strips out repeated boilerplate and irrelevant text, splits the remainder into meaningful chunks using logical breakpoints, and tags each chunk with metadata like voting rules or proxy provisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85c7b20",
   "metadata": {},
   "source": [
    "## 6. Relevance Score Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95218902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevance scorer (sample logic)\n",
    "def calculate_relevance_score(question: str, results: List[Document]) -> float:\n",
    "    if not results:\n",
    "        return 0.0\n",
    "    q_words = set(question.lower().split())\n",
    "    score = 0.0\n",
    "    for doc in results:\n",
    "        d_words = set(doc.page_content.lower().split())\n",
    "        overlap = len(q_words & d_words) / len(q_words)\n",
    "        score += overlap\n",
    "    return score / len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caa7e8f",
   "metadata": {},
   "source": [
    "#### This function calculates how many words the retrieved chunk shares with the query, a basic check for lexical overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15416bbb",
   "metadata": {},
   "source": [
    "## 7. HOA Document Query with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd84b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS query runner\n",
    "def query_hoa_faiss_fixed(question_number: int, hoa_label: str, embed_model=None, chunk_config=\"default\"):\n",
    "    if embed_model is None:\n",
    "        embed_model = setup_embedding_model(silent=True)\n",
    "\n",
    "    hoa_key = hoa_label.lower()\n",
    "    if hoa_key not in FILE_MAP:\n",
    "        return {\"error\": f\"Invalid HOA label: {hoa_label}\"}\n",
    "    if chunk_config not in CHUNK_CONFIGS:\n",
    "        return {\"error\": f\"Unknown chunk config: {chunk_config}\"}\n",
    "\n",
    "    question = QUESTIONS[question_number - 1]\n",
    "    chunk_size = CHUNK_CONFIGS[chunk_config][\"size\"]\n",
    "    chunk_overlap = CHUNK_CONFIGS[chunk_config][\"overlap\"]\n",
    "\n",
    "    try:\n",
    "        url = FILE_MAP[hoa_key]\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        docs = prepare_documents_enhanced(response.text, chunk_size, chunk_overlap)\n",
    "        if not docs:\n",
    "            return {\"error\": \"No content after cleaning and chunking.\"}\n",
    "\n",
    "        vector_store = FAISS.from_documents(docs, embed_model)\n",
    "        results_with_scores = vector_store.similarity_search_with_score(question, k=3)\n",
    "\n",
    "        if not results_with_scores:\n",
    "            return {\"error\": \"No vector hits returned.\"}\n",
    "\n",
    "        top_doc, vector_distance = results_with_scores[0]\n",
    "        \n",
    "        # Convert FAISS distance to similarity score (0-1, higher = better)\n",
    "        # FAISS returns distance (lower = better), so we convert it\n",
    "        semantic_score = max(0.0, 1.0 - vector_distance)\n",
    "        \n",
    "        # Keep lexical as bonus info\n",
    "        lexical_score = calculate_relevance_score(question, [top_doc])\n",
    "        \n",
    "        answer = top_doc.page_content.strip()\n",
    "\n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"score\": semantic_score,  # Use semantic similarity as main score\n",
    "            \"vector_distance\": vector_distance,  # Raw FAISS distance\n",
    "            \"lexical_score\": lexical_score  # Word overlap for reference\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14cabb",
   "metadata": {},
   "source": [
    "#### The RAG loop kicks off by fetching a remote HOA document, then cleaning and chunking it into manageable pieces. Each chunk is embedded and stored in a FAISS index for fast retrieval. When a query arrives, it searches for the most similar chunks and returns the top match along with a relevance score.\n",
    "\n",
    "#### This pipeline wraps ingestion, semantic search, and QA into a streamlined flow. FAISS makes it fast and scalable—ideal for real-time compliance tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd88683a",
   "metadata": {},
   "source": [
    "## 8. Fast Wrapper for Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5411f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick wrapper\n",
    "def quick_query_fixed(question_number: int, hoa_label: str, chunk_config=\"default\", embed_model=None):\n",
    "    return query_hoa_faiss_fixed(question_number, hoa_label, embed_model, chunk_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc061908",
   "metadata": {},
   "source": [
    "#### This helper function streamlines FAISS pipeline execution by forwarding inputs to query_hoa_faiss, enabling rapid prototyping and smooth batch testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e005fee",
   "metadata": {},
   "source": [
    "## 9. Display Query Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4ae8fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 HOA RAG Query System Ready!\n",
      "\n",
      "📋 Available Questions (1-12):\n",
      "  1. How must HOA board elections be conducted under California law?\n",
      "  2. What voting methods are required for board elections?\n",
      "  3. What qualifications are required for board candidates?\n",
      "  4. What notice requirements exist for board meetings?\n",
      "  5. How are proxy votes handled in HOA elections?\n",
      "  6. What constitutes a quorum for member meetings?\n",
      "  7. How long do directors serve on the board?\n",
      "  8. Under what circumstances can a director be removed?\n",
      "  9. What are the assessment collection procedures?\n",
      " 10. How are architectural review requests processed?\n",
      " 11. What enforcement actions can the HOA take for violations?\n",
      " 12. What are the requirements for amending CC&Rs or bylaws?\n",
      "\n",
      "📁 Available HOA Files:\n",
      "   • arroyo park\n",
      "   • camino place\n",
      "   • jackson oaks\n",
      "\n",
      "⚙️ Available Chunk Configs:\n",
      "   • default  → size=800 chars, overlap=200\n",
      "   • small    → size=400 chars, overlap=100\n",
      "   • large    → size=1200 chars, overlap=300\n"
     ]
    }
   ],
   "source": [
    "print(\"🎯 HOA RAG Query System Ready!\")\n",
    "\n",
    "# 📝 Available Questions\n",
    "print(\"\\n📋 Available Questions (1-12):\")\n",
    "for i, q in enumerate(QUESTIONS, 1):\n",
    "    print(f\" {i:2d}. {q}\")\n",
    "\n",
    "# 📁 HOA Files\n",
    "print(\"\\n📁 Available HOA Files:\")\n",
    "for hoa in FILE_MAP.keys():\n",
    "    print(f\"   • {hoa}\")\n",
    "\n",
    "# ⚙️ Chunk Configurations\n",
    "print(\"\\n⚙️ Available Chunk Configs:\")\n",
    "for name, config in CHUNK_CONFIGS.items():\n",
    "    print(f\"   • {name:<8} → size={config['size']} chars, overlap={config['overlap']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d97b21",
   "metadata": {},
   "source": [
    "## 10. Run Example Queries and Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "626bda4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Score: 0.785\n",
      "Vector Distance: 0.215\n",
      "Lexical Score: 0.286\n",
      "Answer: 5.2 Qualifications for Candidates. Candidates for the Board: (i) must be Members in Good Standing, or, in the case of a Member in Good Standing that is an entity, an officer, director, principal, or a...\n"
     ]
    }
   ],
   "source": [
    "# Test with the fixed scoring\n",
    "embed_model = setup_embedding_model(silent=True)\n",
    "result = quick_query_fixed(3, \"arroyo park\", \"small\", embed_model)\n",
    "\n",
    "print(f\"Semantic Score: {result['score']:.3f}\")  # Should be high again\n",
    "print(f\"Vector Distance: {result['vector_distance']:.3f}\")  # Raw FAISS distance  \n",
    "print(f\"Lexical Score: {result['lexical_score']:.3f}\")  # Word overlap\n",
    "print(f\"Answer: {result['answer'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4417f5e5",
   "metadata": {},
   "source": [
    "#### This final test evaluates the RAG pipeline by retrieving an answer to one of the predetermined qeustion selections. The output includes three key metrics: a semantic score (0.785) indicating strong alignment between the query and the returned text based on shared meaning; a vector Euclidean distance (0.215) from FAISS, showing high similarity in embedding space; and a lexical score (0.286), which reflects moderate word overlap. Together, these metrics confirm that the model retrieved a semantically relevant answer, even if some phrasing differs from the original question—demonstrating the strength of embedding-based search over simple keyword matching."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
